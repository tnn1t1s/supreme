#!/usr/bin/env python3
"""decision-rag: RAG retriever for Supreme Court decision blocks with structured metadata.

Ingests blocks from docs/decision/*/blocks/, parses YAML frontmatter as metadata,
builds a vector index with metadata filters, and supports filtered queries.

Usage:
  decision-rag ingest                                    # Index all decision blocks
  decision-rag query "taxing power"                      # Query across all opinions
  decision-rag query "taxing power" -j Roberts           # Filter by justice
  decision-rag query "major questions" -t dissent         # Filter by opinion type
  decision-rag query "IEEPA" -j Gorsuch -j Barrett       # Multiple justice filter
  decision-rag query "IEEPA" -d nondelegation            # Filter by doctrine tag
  decision-rag query "delegation" -d major_questions -j Thomas  # Combined filters
  decision-rag list                                      # List indexed opinions

Doctrine tags: major_questions, clear_statement, nondelegation, separation_of_powers,
               taxing_power, statutory_interpretation, foreign_affairs, emergency_powers,
               congressional_delegation
"""

import argparse
import json
import re
import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
DECISION_DIR = PROJECT_ROOT / "docs" / "decision"
INDEX_DIR = PROJECT_ROOT / ".rag_index_decision"


def parse_frontmatter(text):
    match = re.match(r"^---\n(.*?)\n---\n(.*)", text, re.DOTALL)
    if not match:
        return {}, text
    yaml_block = match.group(1)
    body = match.group(2).strip()
    metadata = {}
    for line in yaml_block.split("\n"):
        if ":" in line:
            key, val = line.split(":", 1)
            val = val.strip().strip('"').strip("'")
            metadata[key.strip()] = val
    return metadata, body


def load_blocks():
    from llama_index.core import Document
    docs = []
    for decision_dir in sorted(DECISION_DIR.iterdir()):
        blocks_dir = decision_dir / "blocks"
        if not blocks_dir.exists():
            continue
        for opinion_dir in sorted(blocks_dir.iterdir()):
            if not opinion_dir.is_dir():
                continue
            for block_file in sorted(opinion_dir.glob("*.md")):
                text = block_file.read_text()
                metadata, body = parse_frontmatter(text)
                if not body.strip():
                    continue
                metadata["file_path"] = str(block_file.relative_to(PROJECT_ROOT))
                doc = Document(text=body, metadata=metadata)
                docs.append(doc)
    return docs


def get_settings():
    from llama_index.core import Settings
    from llama_index.embeddings.huggingface import HuggingFaceEmbedding
    Settings.embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-en-v1.5")
    Settings.llm = None
    return Settings


def build_index():
    from llama_index.core import VectorStoreIndex, StorageContext
    get_settings()
    docs = load_blocks()
    if not docs:
        print("ERROR: No blocks found", file=sys.stderr)
        sys.exit(1)
    index = VectorStoreIndex.from_documents(docs)
    INDEX_DIR.mkdir(exist_ok=True)
    index.storage_context.persist(persist_dir=str(INDEX_DIR))
    justices = set()
    types = set()
    for d in docs:
        justices.add(d.metadata.get("justice", ""))
        types.add(d.metadata.get("opinion_type", ""))
    print(f"Indexed {len(docs)} blocks")
    print(f"  Justices: {', '.join(sorted(justices))}")
    print(f"  Types: {', '.join(sorted(types))}")
    print(f"  Index: {INDEX_DIR}")
    return index


def load_index():
    from llama_index.core import StorageContext, load_index_from_storage
    get_settings()
    if not INDEX_DIR.exists():
        print("No index found. Building...", file=sys.stderr)
        return build_index()
    storage_context = StorageContext.from_defaults(persist_dir=str(INDEX_DIR))
    return load_index_from_storage(storage_context)


def retrieve_filtered(index, query, justices=None, opinion_types=None, doctrines=None, top_k=10):
    from llama_index.core.vector_stores import MetadataFilters, MetadataFilter, FilterOperator, FilterCondition

    filters_list = []
    if justices:
        for j in justices:
            filters_list.append(MetadataFilter(key="justice", value=j, operator=FilterOperator.EQ))
    if opinion_types:
        for t in opinion_types:
            filters_list.append(MetadataFilter(key="opinion_type", value=t, operator=FilterOperator.EQ))
    if doctrines:
        for d in doctrines:
            filters_list.append(MetadataFilter(key="doctrines_primary", value=d, operator=FilterOperator.CONTAINS))

    if filters_list:
        metadata_filters = MetadataFilters(filters=filters_list, condition=FilterCondition.OR if len(filters_list) > 1 else FilterCondition.AND)
        retriever = index.as_retriever(similarity_top_k=top_k, filters=metadata_filters)
    else:
        retriever = index.as_retriever(similarity_top_k=top_k)

    nodes = retriever.retrieve(query)

    if doctrines and not filters_list:
        filtered = []
        for node in nodes:
            primary = node.metadata.get("doctrines_primary", "")
            secondary = node.metadata.get("doctrines_secondary", "")
            all_doctrines = primary + "," + secondary
            if any(d in all_doctrines for d in doctrines):
                filtered.append(node)
        return filtered

    return nodes


def format_node(i, node):
    m = node.metadata
    primary = m.get("doctrines_primary", "none")
    secondary = m.get("doctrines_secondary", "none")
    lines = [
        f"--- NODE {i+1} | score={node.score:.4f} ---",
        f"  justice: {m.get('justice', '?')}",
        f"  opinion_type: {m.get('opinion_type', '?')}",
        f"  title: {m.get('title', '?')}",
        f"  block_id: {m.get('block_id', '?')}",
        f"  pages: {m.get('page_start', '?')}-{m.get('page_end', '?')}",
        f"  doctrines: [{primary}]" + (f" + [{secondary}]" if secondary != "none" else ""),
        "",
        node.text[:1500],
        "",
    ]
    return "\n".join(lines)


def cmd_ingest(args):
    build_index()


def cmd_query(args):
    index = load_index()
    nodes = retrieve_filtered(
        index, args.query,
        justices=args.justice,
        opinion_types=args.type,
        doctrines=args.doctrine,
        top_k=args.top_k,
    )
    if args.json:
        out = []
        for node in nodes:
            out.append({
                "score": round(node.score, 4),
                "metadata": node.metadata,
                "text": node.text[:2000],
            })
        print(json.dumps(out, indent=2))
    else:
        print(f"=== QUERY: {args.query} ===")
        if args.justice:
            print(f"  Filter justice: {', '.join(args.justice)}")
        if args.type:
            print(f"  Filter type: {', '.join(args.type)}")
        if args.doctrine:
            print(f"  Filter doctrine: {', '.join(args.doctrine)}")
        print()
        for i, node in enumerate(nodes):
            print(format_node(i, node))
        print(f"{'='*60}")
        print(f"  {len(nodes)} results | top_k={args.top_k}")


def cmd_list(args):
    manifest_files = list(DECISION_DIR.glob("*/manifest.json"))
    if not manifest_files:
        print("No decisions indexed")
        return
    for mf in manifest_files:
        manifest = json.loads(mf.read_text())
        print(f"Case: {manifest['case']}")
        print(f"Docket: {', '.join(manifest['docket'])}")
        print(f"Decided: {manifest['decided']}")
        print(f"Opinions:")
        for op in manifest["opinions"]:
            print(f"  {op['justice']:12s} {op['type']:25s} {op['block_count']:3d} blocks  pp.{op['page_range'][0]}-{op['page_range'][1]}")
        print(f"Total blocks: {len(manifest.get('blocks', []))}")


def main():
    parser = argparse.ArgumentParser(prog="decision-rag", description="RAG for Supreme Court decisions")
    sub = parser.add_subparsers(dest="command", required=True)

    p_ingest = sub.add_parser("ingest", help="Index decision blocks")
    p_ingest.set_defaults(func=cmd_ingest)

    p_query = sub.add_parser("query", help="Query with metadata filters")
    p_query.add_argument("query", help="Search query")
    p_query.add_argument("-j", "--justice", action="append", help="Filter by justice (repeatable)")
    p_query.add_argument("-t", "--type", action="append", help="Filter by opinion type (repeatable)")
    p_query.add_argument("-d", "--doctrine", action="append",
                         help="Filter by doctrine tag (repeatable). Values: major_questions, clear_statement, "
                              "nondelegation, separation_of_powers, taxing_power, statutory_interpretation, "
                              "foreign_affairs, emergency_powers, congressional_delegation")
    p_query.add_argument("-k", "--top-k", type=int, default=10)
    p_query.add_argument("--json", action="store_true")
    p_query.set_defaults(func=cmd_query)

    p_list = sub.add_parser("list", help="List indexed decisions")
    p_list.set_defaults(func=cmd_list)

    args = parser.parse_args()
    args.func(args)


if __name__ == "__main__":
    main()
